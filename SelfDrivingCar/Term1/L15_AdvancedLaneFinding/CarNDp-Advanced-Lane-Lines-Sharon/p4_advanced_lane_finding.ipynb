{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Advance Lane Line Finding** \n",
    "\n",
    "***\n",
    "In this project, your goal is to write a software pipeline to identify the lane boundaries in a video from a front-facing camera on a car. The camera calibration images, test road images, and project videos are available in the project repository. There is an writeup template in the repostitory provided as a starting point for your writeup of the project.\n",
    "\n",
    "---\n",
    "Steps:\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply the distortion correction to the raw image.  \n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\"). \n",
    "* Detect lane pixels and fit to find lane boundary.\n",
    "* Determine curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import ntpath\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilies Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def camera_calibration():\n",
    "    nx = 9 # of inner corners in x\n",
    "    ny = 6 # of inner corners in y\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((ny*nx,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob('camera_cal/*.jpg')\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            # Draw and display the corners\n",
    "            cv2.drawChessboardCorners(img, (nx,ny), corners, ret)\n",
    "            directory = 'output_images/1_corners_found/'\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            write_name = directory+'corners_found'+str(idx)+'.jpg'\n",
    "            cv2.imwrite(write_name, img)\n",
    "    cv2.destroyAllWindows()\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],None,None)\n",
    "    return mtx, dist\n",
    "\n",
    "\n",
    "# UNDISTORT \n",
    "def cal_undistort(img, mtx, dist):\n",
    "    undist = cv2.undistort(img, mtx, dist, None, None)\n",
    "    return undist\n",
    "\n",
    "# COLOR \n",
    "def abs_sobel_thresh(img, orient='x', thresh=(0, 255)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    #print(scaled_sobel)\n",
    "    # Create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    plt.figure(figsize=(5,5))\n",
    "    #plt.imshow(binary_output, cmap='gray')\n",
    "    #print(binary_output)\n",
    "    return binary_output\n",
    "\n",
    "def hls_select(img, thresh=(0, 255)):\n",
    "    # 1) Convert to HLS color space\n",
    "    # 2) Apply a threshold to the S channel\n",
    "    # 3) Return a binary image of threshold result\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    binary_output = np.zeros_like(s_channel)\n",
    "    binary_output[(s_channel > thresh[0]) & (s_channel <= thresh[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "# color space and gradient\n",
    "def color_space_and_gradient(img, orient, grad_thresh=(20, 100), color_thresh=(170, 255)):\n",
    "    img = np.copy(img)\n",
    "    # Convert to HSV color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS).astype(np.float)\n",
    "    l_channel = hls[:,:,1]\n",
    "    #s_channel = hsv[:,:,2]\n",
    "    \n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV).astype(np.float)\n",
    "    h_channel = hsv[:,:,0]\n",
    "    s_channel = hsv[:,:,1]\n",
    "    v_channel = hsv[:,:,2]\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).astype(np.float)\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))# Take the derivative in x and Absolute x derivative to accentuate lines away from horizontal\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobel))\n",
    "    \n",
    "    # Threshold gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= grad_thresh[0]) & (scaled_sobel <= grad_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(h_channel)\n",
    "    s_binary[(s_channel >= color_thresh[0]) & (s_channel <= color_thresh[1])] = 1\n",
    "    \n",
    "    # Stack each channel\n",
    "    # Note color_binary[:, :, 0] is all 0s, effectively an all black image. It might\n",
    "    # be beneficial to replace this channel with something else.\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary))\n",
    "    return color_binary\n",
    "\n",
    "def warp(image, src, dst):\n",
    "    #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = image\n",
    "    # Grab the image shape\n",
    "    img_size = (gray.shape[1], gray.shape[0])\n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    warped = cv2.warpPerspective(image, M, img_size)\n",
    "    return warped\n",
    "\n",
    "# Save Images:\n",
    "def save_images(image, fname, directory, isBinary = 'false'):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        write_name = directory + fname +'.jpg'\n",
    "        cv2.imwrite(write_name, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 1: Camera Calibration\n",
    "mtx, dist = camera_calibration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build the pipline\n",
    "def FindLaneLinesAdvanced(image, fname, mtx, dist, orient, grad_thresh, color_thresh, src, dst):\n",
    "    undist = cal_undistort(image, mtx, dist)\n",
    "    save_images(undist, fname, 'output_images/2_distortion_corrected/')    \n",
    "    color_binary = color_space_and_gradient(undist,'x', grad_thresh, color_thresh)\n",
    "    save_images(color_binary, fname, 'output_images/3_color_transforms/', 'true')\n",
    "    #birdseye = warp(color_binary, src, dst)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(undist)\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(color_binary)\n",
    "    ax2.set_title('Threshold', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    #histogram = np.sum(birdseye[birdseye.shape[0]/2:,:], axis=0) \n",
    "    #plt.figure()\n",
    "    #plt.plot(histogram)\n",
    "    return birdseye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'abs_sobelx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-59b05f3b62e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m215\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m715\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m715\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m606\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m431\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m676\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m431\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m720\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1080\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m720\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1080\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mbirdseye\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFindLaneLinesAdvanced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m                                          \u001b[0;34m(\u001b[0m\u001b[0;36m170\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m#plt.imshow(output, cmap = 'gray')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-18d949cdf293>\u001b[0m in \u001b[0;36mFindLaneLinesAdvanced\u001b[0;34m(image, fname, mtx, dist, orient, grad_thresh, color_thresh, src, dst)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mundist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcal_undistort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msave_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mundist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output_images/2_distortion_corrected/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcolor_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor_space_and_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mundist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_thresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_thresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msave_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output_images/3_color_transforms/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'true'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#birdseye = warp(color_binary, src, dst)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-ab446552e074>\u001b[0m in \u001b[0;36mcolor_space_and_gradient\u001b[0;34m(img, orient, grad_thresh, color_thresh)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mabs_sobel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSobel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCV_64F\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mscaled_sobel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mabs_sobelx\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_sobel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# Threshold gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'abs_sobelx' is not defined"
     ]
    }
   ],
   "source": [
    "# Test with test images\n",
    "for f in os.listdir(\"test_images/\"):\n",
    "    if not f.startswith('.'):\n",
    "        image = cv2.imread('test_images/'+f)\n",
    "        src = np.float32([(215, 715), (1120, 715), (606, 431), (676, 431)])\n",
    "        dst = np.float32([(200, 720), (1080, 720), (200, -500), (1080, -500)])\n",
    "        birdseye = FindLaneLinesAdvanced(image, f, mtx, dist, 'x', \\\n",
    "                                         (170, 255), (20, 100), src, dst)\n",
    "        #plt.imshow(output, cmap = 'gray') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos\n",
    "\n",
    "You know what's cooler than drawing lanes over images? Drawing lanes over video!\n",
    "\n",
    "We can test our solution on two provided videos:\n",
    "\n",
    "`project_video.mp4`\n",
    "\n",
    "`challenge_video.mp4`\n",
    "\n",
    "`harder_challenge_video.mp4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image with lines are drawn on lanes)\n",
    "    imshape = image.shape\n",
    "    #lines_edges = findLaneLines(image,5,50,150,\\\n",
    "                  #vertices,10, np.pi/180, 10, 35,20)\n",
    "    output = image\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project_output = 'project_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "project_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
